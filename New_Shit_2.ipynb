{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Matrix Factorization Code from Set 5\n",
    "\n",
    "Y_train = np.loadtxt('train.txt').astype(int)\n",
    "Y_test = np.loadtxt('test.txt').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_U(Ui, Yij, Vj, reg, eta, Ai, Bj, bias):\n",
    "    \"\"\"\n",
    "    Takes as input Ui (the ith row of U), a training point Yij, the column\n",
    "    vector Vj (jth column of V^T), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Ui multiplied by eta.\n",
    "    \"\"\"\n",
    "    \n",
    "    if bias == False:\n",
    "        Ai = 0\n",
    "        Bj = 0\n",
    "        \n",
    "    return eta*(reg*Ui - np.dot(Vj, (Yij - np.dot(Ui, Vj) + Ai + Bj)))\n",
    "\n",
    "def grad_V(Vj, Yij, Ui, reg, eta, Ai, Bj, bias):\n",
    "    \"\"\"\n",
    "    Takes as input the column vector Vj (jth column of V^T), a training point Yij,\n",
    "    Ui (the ith row of U), reg (the regularization parameter lambda),\n",
    "    and eta (the learning rate).\n",
    "\n",
    "    Returns the gradient of the regularized loss function with\n",
    "    respect to Vj multiplied by eta.\n",
    "    \"\"\"\n",
    "    if bias == False:\n",
    "        Ai = 0\n",
    "        Bj = 0\n",
    "        \n",
    "    return eta*(reg*Vj - np.dot(Ui,(Yij - np.dot(Ui, Vj) + Ai + Bj)))\n",
    "\n",
    "def grad_A(Vj, Yij, Ui, reg, eta, Ai, Bj):\n",
    "\n",
    "    return eta*(Yij - (np.dot(Ui,Vj) + Ai + Bj))\n",
    "\n",
    "def grad_B(Vj, Yij, Ui, reg, eta, Ai, Bj):\n",
    "\n",
    "    return eta*(Yij - (np.dot(Ui,Vj) + Ai + Bj))\n",
    "\n",
    "def get_err(U, V, Y, A, B, bias, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "    if bias: \n",
    "        first_term = 0.5*reg*(np.linalg.norm(U, ord='fro')**2 + np.linalg.norm(V, ord='fro')**2)\n",
    "        second_term = 0\n",
    "        for index in range(len(Y)):\n",
    "            (i, j, Yij) = Y[index]\n",
    "            second_term += (0.5 * (Yij - (np.dot(U[i - 1], V[j - 1])) + A[i-1] + B[j-1])**2)\n",
    "        return (first_term + second_term)/len(Y)\n",
    "    \n",
    "    else:\n",
    "        first_term = 0.5*reg*(np.linalg.norm(U, ord='fro')**2 + np.linalg.norm(V, ord='fro')**2)\n",
    "        second_term = 0\n",
    "        for index in range(len(Y)):\n",
    "            (i, j, Yij) = Y[index]\n",
    "            second_term += (0.5 * (Yij - (np.dot(U[i - 1], V[j - 1]))))\n",
    "        return (first_term + second_term)/len(Y)\n",
    "\n",
    "\n",
    "def get_err_bias(U, V, Y, A, B, bias, reg=0.0):\n",
    "    \"\"\"\n",
    "    Takes as input a matrix Y of triples (i, j, Y_ij) where i is the index of a user,\n",
    "    j is the index of a movie, and Y_ij is user i's rating of movie j and\n",
    "    user/movie matrices U and V.\n",
    "\n",
    "    Returns the mean regularized squared-error of predictions made by\n",
    "    estimating Y_{ij} as the dot product of the ith row of U and the jth column of V^T.\n",
    "    \"\"\"\n",
    "\n",
    "    first_term = 0.5*reg*(np.linalg.norm(U, ord='fro')**2 + np.linalg.norm(V, ord='fro')**2)\n",
    "    second_term = 0\n",
    "    for index in range(len(Y)):\n",
    "        (i, j, Yij) = Y[index]\n",
    "        second_term += (0.5 * (Yij - (np.dot(U[i - 1], V[j - 1])) + A[i-1] + B[j-1])**2)\n",
    "    return (first_term + second_term)/len(Y)\n",
    "\n",
    "\n",
    "\n",
    "def train_model(M, N, K, eta, reg, Y, bias, eps=0.001, max_epochs=300):\n",
    "    \"\"\"\n",
    "    Given a training data matrix Y containing rows (i, j, Y_ij)\n",
    "    where Y_ij is user i's rating on movie j, learns an\n",
    "    M x K matrix U and N x K matrix V such that rating Y_ij is approximated\n",
    "    by (UV^T)_ij.\n",
    "\n",
    "    Uses a learning rate of <eta> and regularization of <reg>. Stops after\n",
    "    <max_epochs> epochs, or once the magnitude of the decrease in regularized\n",
    "    MSE between epochs is smaller than a fraction <eps> of the decrease in\n",
    "    MSE after the first epoch.\n",
    "\n",
    "    Returns a tuple (U, V, err) consisting of U, V, and the unregularized MSE\n",
    "    of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    A = np.random.uniform(-0.5, 0.5, size = (M, ))\n",
    "    B = np.random.uniform(-0.5, 0.5, size = (N, ))\n",
    "        \n",
    "    U = np.random.uniform(-0.5, 0.5, size = (M, K))\n",
    "    V = np.random.uniform(-0.5, 0.5, size = (N, K))\n",
    "    \n",
    "    \n",
    "    MSE_before = get_err_bias(U, V, Y, A, B, bias, reg)\n",
    "    for epoch in range(max_epochs):\n",
    "        print(epoch)\n",
    "        print(MSE_before)\n",
    "        \n",
    "#         print(\"U:\", U[0,:])\n",
    "#         print(\"V:\", V[0,:])\n",
    "        np.random.shuffle(Y)\n",
    "        for index in range(len(Y)):\n",
    "            (i, j, Yij) = Y[index]\n",
    "            # Updates with gradient descent\n",
    "            u_grad = grad_U(U[i-1], Yij, V[j-1], reg, eta, A[i-1], B[i-1], bias)\n",
    "            v_grad = grad_V(V[j-1], Yij, U[i-1], reg, eta, A[i-1], B[i-1], bias)\n",
    "            a_grad = grad_A(V[j-1], Yij, U[i-1], reg, eta, A[i-1], B[j-1])\n",
    "            b_grad = grad_B(V[j-1], Yij, U[i-1], reg, eta, A[i-1], B[j-1])\n",
    "            A[i - 1] = A[i - 1] - a_grad\n",
    "            B[j - 1] = B[j - 1] - b_grad\n",
    "            U[i - 1] = U[i-1] - u_grad\n",
    "            V[j - 1] = V[j-1] - v_grad\n",
    "        print(A[0:3], B[0:3])\n",
    "            \n",
    "        MSE_after = get_err(U, V, Y, A, B, bias, reg)\n",
    "        difference = MSE_before - MSE_after\n",
    "        if epoch == 0:\n",
    "            epoch1_MSE_diff = difference\n",
    "        if difference/epoch1_MSE_diff <= eps:\n",
    "            break\n",
    "        MSE_before = MSE_after\n",
    "\n",
    "    return U, V, MSE_before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with M = 943, N = 1682, k = 20, eta = 0.03, reg = 0.01\n",
      "0\n",
      "7.043492599258072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:126: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan] [nan nan nan]\n",
      "1\n",
      "nan\n",
      "[nan nan nan] [nan nan nan]\n",
      "2\n",
      "nan\n",
      "[nan nan nan] [nan nan nan]\n",
      "3\n",
      "nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-6d1861f2f179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mKs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m#E_ins_for_lambda.append(e_in)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0meout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-f154319753a9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(M, N, K, eta, reg, Y, bias, eps, max_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mv_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0ma_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mb_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-f154319753a9>\u001b[0m in \u001b[0;36mgrad_B\u001b[0;34m(Vj, Yij, Ui, reg, eta, Ai, Bj)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrad_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYij\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mAi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "M = max(max(Y_train[:,0]), max(Y_test[:,0])).astype(int) # users\n",
    "N = max(max(Y_train[:,1]), max(Y_test[:,1])).astype(int) # movies\n",
    "\n",
    "\n",
    "\n",
    "#U,V, err = train_model(M, N, K, eta, reg, Y_train)\n",
    "\n",
    "\n",
    "#Ks = [10,20,30,50,100]\n",
    "Ks = [20]\n",
    "#regs = [10**-4, 10**-3, 10**-2, 10**-1, 1]\n",
    "regs = [0.01]\n",
    "eta = 0.03 # learning rate\n",
    "#E_ins = []\n",
    "#E_outs = []\n",
    "\n",
    "bias = True\n",
    "# Use to compute Ein and Eout\n",
    "for reg in regs:\n",
    "    #E_ins_for_lambda = []\n",
    "    #E_outs_for_lambda = []\n",
    "\n",
    "    for k in Ks:\n",
    "        print(\"Training model with M = %s, N = %s, k = %s, eta = %s, reg = %s\"%(M, N, k, eta, reg))\n",
    "        U,V, e_in = train_model(M, N, k, eta, reg, Y_train, bias)\n",
    "        #E_ins_for_lambda.append(e_in)\n",
    "        eout = get_err(U, V, Y_test, 0,0, bias)\n",
    "        #E_outs_for_lambda.append(eout)\n",
    "\n",
    "    #E_ins.append(E_ins_for_lambda)\n",
    "    #E_outs.append(E_outs_for_lambda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
